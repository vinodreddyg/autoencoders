{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "e4f39475-bc12-434f-be6e-fb0320552a14"
    }
   },
   "outputs": [],
   "source": [
    "# Inspired from https://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder/\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7b3780df-b300-477b-813f-d1bba2ac7627"
    }
   },
   "outputs": [],
   "source": [
    "encoding_dim = 256\n",
    "\n",
    "input_img = Input(shape = (784,))\n",
    "encoded = Dense(encoding_dim, activation='relu', name='encoder')(input_img)\n",
    "decoded = Dense(784, activation='sigmoid', name='decoder')(encoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "611bbfd5-8391-44d4-a700-de2885da80ab"
    }
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "lam = 0.001\n",
    "\n",
    "def contractive_loss(y_true, y_pred):\n",
    "    base_error = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    h = autoencoder.get_layer('encoder').output\n",
    "    W = K.variable(value = autoencoder.get_layer('encoder').get_weights()[0])\n",
    "    W = K.transpose(W)\n",
    "    factor = K.sign(h)\n",
    "    factor = (factor + 1)/2\n",
    "    contractive_error = lam*K.sum(factor * K.sum(W**2, axis=1), axis=1)\n",
    "    \n",
    "    return base_error + contractive_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3a9e304e-4c09-416d-bc31-4bed6467cb3d"
    }
   },
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "\n",
    "# Decoder model\n",
    "decoder_layer = autoencoder.get_layer('decoder')\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "18b418e6-4176-4848-873d-44f3c10017c6"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer = Adam(lr=0.001, decay = 0.0001), loss=contractive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "20de0e86-cbf7-4e18-8af9-ff6fee45097d"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test,_) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "6f7f35f7-9e7c-4830-b218-a01432f625c8"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3675afc3-5a34-49da-977d-22cfe9315170"
    }
   },
   "outputs": [],
   "source": [
    "weights,biases = autoencoder.get_layer('encoder').get_weights()\n",
    "weights = weights.T\n",
    "weights = weights.T.reshape((len(weights), 28, 28))\n",
    "\n",
    "pixeled_weights = np.heaviside(weights, 0.5)*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "394f4e9d-0542-45df-8b3f-dc53b4726dfc"
    }
   },
   "outputs": [],
   "source": [
    "encoder_imgs = encoder.predict(x_test)\n",
    "decoder_imgs = decoder.predict(encoder_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "53c07cce-f153-4ba1-a060-c2d9494c4002"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def show_imgs(n, r, c, imgs):\n",
    "    plt.figure(figsize=(2*c, 2*c))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(r,c,i+1)\n",
    "        plt.imshow(imgs[i])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1ae6a102-7385-4638-b7d1-2671b1053261"
    }
   },
   "outputs": [],
   "source": [
    "show_imgs(10,1,10,x_test[0:10].reshape((10,28,28)))\n",
    "show_imgs(10,1,10,decoder_imgs[0:10].reshape((10,28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "2f049e65-7aa5-447e-ae90-244c485e500d"
    }
   },
   "outputs": [],
   "source": [
    "show_imgs(encoding_dim, 16, 16, pixeled_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p27]",
   "language": "python",
   "name": "conda-env-tensorflow_p27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
